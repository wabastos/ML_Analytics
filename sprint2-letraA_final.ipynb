{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5581d1b0",
   "metadata": {},
   "source": [
    "# Curso: Ciência de Dados e Analytics (PUC Rio)\n",
    "## Sprint: Machine Learning & Analytics\n",
    "#### Professores:\n",
    "> Profs. Drs. Augusto Baffa, Luiz Schirmer,Jonatas Grosman e Tatiana Escovedo\n",
    "\n",
    "\n",
    "#### Aluno:\n",
    "> Wellington Bastos, M.Sc.\n",
    "\n",
    "## Abrangência:\n",
    "\n",
    "###  SPRINT II - MVP - letras a - modelo utilizando métodos clássicos para um problema de classificação ou regressão \n",
    "\n",
    "**Problema**: Como medir e acompanhar a qualidade do serviço de dados fornecido pelas prestadoras de banda larga, em específico das prestadoras de rede móvel? A Anatel estabeleceu um conjunto de indicadores de qualidade (RQUAL) para fiscalizar, acompanhar e divulgar o desempenho do serviço de telecomunicações https://www.gov.br/anatel/pt-br/dados/qualidade/qualidade-dos-servicos/sobre-o-rqual \n",
    "\n",
    "**Motivação**: As empresas de Telecomunicações, denominadas como Grupos Detentores de Participação de Mercado Nacional (TIM, CLARO, OI, VIVO e SKY), serão avaliadas conforme os parâmetros e indicadores definidos no RQUAL, cujo resultado se desdobrará em uma classificação através de selo de qualidade. Portanto, é importante e fundamental para as prestadoras definirem e acompanharem os KPI's de qualidade para definirem as ações de melhoramento da rede de telecomunicações. O RQUAL definie o conjunto de KPI's, como são coletados, agregados e valores de referência no documento MOP_v2-0.zip (https://sistemas.anatel.gov.br/anexar-api/publico/anexos/download/b8c8a0b5652cc3ec673d463fac657ffe).\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/wabastos/ML_Analytics/main/Figura_1.bmp)\n",
    "\n",
    "**Escopo**: O trabalho definido para o Sprint II (letra a) atuará em um conjunto de KPI's específicos do RQUAL denominado INF5, que está relacionado com a experiência de uso das aplicações mais utilizadas pelo clientes das redes móveis ou rede fixa. O INF5 é subdividido de INF-1 até INF5-5, com cada indicador representando a experíencia dos seguintes aplicativos:\n",
    "\n",
    "> - INF5-1:\texperiencia do uso de aplicativos em redes de dados - navegacao web\n",
    "> - INF5-2:\texperiencia do uso de aplicativos em redes de dados - redes sociais\n",
    "> - INF5-3:\texperiencia do uso de aplicativos em redes de dados - carregar videos hd (streaming)\n",
    "> - INF5-4:\texperiencia do uso de aplicativos em redes de dados - chamadas de video (videoconferencia)\n",
    "> - INF5-5:\texperiencia do uso de aplicativos em redes de dados - jogos online\n",
    "\n",
    "Esses indicadores podem ser obtidos em downllload a partir do site da Anatel (URL:https://www.anatel.gov.br/dadosabertos/paineis_de_dados/qualidade/indicadores_rqual.zip). Na mesma página pode ser encontrado um dashboard que permite explorar todos os KPI's. Os detalhes dos INF5 estão disponíveis no Anexo_05_IND4_IND5_IND6_IND7_INF4_INF_5_SMP_v2.0.docx que consta da norma MOP_v2-0.zip, cujo link já foi indicado acima nesse documento. Nesse trabalho será dado enfoque apenas a rede móvel, contudo a mesma abordagem se aplica a rede fixa.\n",
    "\n",
    "**Descrição e Hipótese**: \n",
    "\n",
    "A partir dos indicadores IFN5 é possível definir perfil de desempenho e qualidade das operadoras por vários critérios como Município, UF e Prestadora considerando os resultados obtidos através do uso dos aplicativos de usuários. Dessa maneira, algumas abordagens são possíveis, como:\n",
    "\n",
    "1. Classificação de prestadoras: pode ser usado algoritmos de classificação, como Regressão Logística, Árvores de Decisão, Random Forest e outros, para prever a prestadora com base nos atributos fornecidos, como \"Indicador\", \"Município\", \"UF\" e \"Resultado\". Isso pode ajudar a identificar padrões e características distintas de cada prestadora em relação aos indicadores de qualidade. Adicionalmente, pode ser acrescido atributos de data que podem auxiliar no entendimento de progressão do indicador.\n",
    "\n",
    "1. Previsão de resultados: com base nos outros atributos fornecidos, pode se construir modelos de regressão, como Regressão Linear, Árvore de Decisão, Random Forest para prever os resultados dos indicadores de qualidade. Por exemplo, pode-se tentar prever a experiência do uso de aplicativos em redes de dados com base em atributos como \"Número de Coletores\" e \"Número de Medidas\".\n",
    "\n",
    "1. Análise de tendências: utilizando técnicas de séries temporais para analisar as tendências dos indicadores de qualidade ao longo do tempo. Isso pode envolver a aplicação de modelos como ARIMA (Médias Móveis Integradas Autoregressivas) ou modelos de suavização exponencial para prever o desempenho futuro dos indicadores.\n",
    "\n",
    "1. Clusterização de municípios: com dados de vários municípios, aplicando algoritmos de clusterização, como K-means ou DBSCAN, para agrupar os municípios com base nos indicadores de qualidade. Isso pode ajudar a identificar padrões geográficos ou semelhanças entre os municípios.\n",
    "\n",
    "1. Análise de importância de atributos: também pode se utilizar algoritmos como Árvores de Decisão ou Random Forest para determinar a importância de cada atributo na previsão dos resultados dos indicadores de qualidade. Isso pode ajudar a identificar quais atributos têm maior influência nos resultados e auxiliar na tomada de decisões.\n",
    "\n",
    "O trabalho desenvolvido na sequência será limitado ao escopo do **Sprint 2 - letra a**, portanto, daremos foco ao item 1 acima, em que será buscado um modelo de classificação seguindo as seguintes etapas:\n",
    "\n",
    "- Preparação de dados\n",
    "- Definição das variáveis preditoras e alvo\n",
    "- Dividir o conjunto de dados em treino e teste\n",
    "- Pré-processar dados para codificar as variáveis categóricas em numéricos\n",
    "- Definir Pipeline de pré-processamento e modelos\n",
    "- Executar os modelos para gerar o score\n",
    "- Gerar os relatórios para avaliação\n",
    "- Plotar os resultados de score obtidos pelos modelos\n",
    "- Escolher o melhor modelo\n",
    "- Aplicar os dados de teste ao modelo selecionado\n",
    "- Propor um método de avaliação dos municípios a partir de equivalência. Aqui vamos assumir a hipótese de que é possível avaliar o perfil de indicadores dos municípios por equivalência a um conjunto de municípios treinamedos em ML.\n",
    "\n",
    "**Restrições**:\n",
    "\n",
    "- Embora tenhamos utilizado dados reais provenientes de uma agência pública, é importante ressaltar que as informações e resultados apresentados neste estudo são puramente especulativos no âmbito acadêmico. Eles não possuem qualquer vínculo com as operadoras ou com o órgão responsável pela geração dos dados.\n",
    "\n",
    "- Devido ao tamanho do conjunto de dados, optamos por restringir a aplicação do treinamento dos modelos a apenas uma classe de municípios, mais especificamente as capitais brasileiras. Essa abordagem é suficiente para trabalhar com todos os conceitos estudados durante a disciplina.\n",
    "\n",
    "- O método de análise proposto para a aplicação dos modelos é especulativo e não garante que seus resultados sejam aplicáveis na prática. Ele representa apenas uma tentativa de encontrar um caminho para minimizar a aplicação do modelo de aprendizado de máquina a toda a base de dados, levando em consideração o alto custo computacional que isso acarretaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff2bc26a",
   "metadata": {},
   "source": [
    "## Importando as bibliotecas\n",
    "\n",
    "O conjunto de bibliotecas utilizado no código inclui:\n",
    "1. pandas para manipulação e análise de dados; \n",
    "1. numpy para operações numéricas e manupulação de arrays multidimensionais;\n",
    "\n",
    "Além dessas, faz uso de várias bibliotecas do scikit-learn para pré-processamento, modelagem e avaliação de modelos de aprendizado de máquina como: \n",
    "1. LabelEncoder, OneHotEncoder e OrdinalEncoder para codificação de variáveis categóricas;\n",
    "1. StandardScaler para escalonamento de dados numéricos; \n",
    "1. train_test_split para divisão dos dados em conjuntos de treinamento e teste; \n",
    "1. Pipeline e ColumnTransformer para criação de pipelines de pré-processamento; \n",
    "1. RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, LogisticRegression, DecisionTreeClassifier, KNeighborsClassifier, GaussianNB e SVC para diferentes algoritmos de classificação; \n",
    "1. accuracy_score, precision_score, recall_score e f1_score para métricas de avaliação de modelos; \n",
    "1. GridSearchCV para busca em grid de hiperparâmetros; \n",
    "1. classification_report para relatório de classificação, e \n",
    "1. matplotlib.pyplot para visualização de resultados em gráficos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b612a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uso geral\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import markdown\n",
    "import joblib\n",
    "\n",
    "#Gráficos\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Pré-processamentode dados\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Machine Leaning\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, KFold\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier, ExtraTreesClassifier, AdaBoostClassifier, VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n",
    "from kmodes.kmodes import KModes\n",
    "\n",
    "\n",
    "# Estatística e Análise de dados\n",
    "from scipy.stats import f_oneway\n",
    "from scipy.stats import chi2_contingency\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "afa9daf1",
   "metadata": {},
   "source": [
    "## Carga dos Dados\n",
    "\n",
    "### O Dataset\n",
    "\n",
    "Os dados utilizados foram obtidos na base de dados da ANATEL referentes aos indicadores RQUAL, cujo *shape* é de 6.778.003 registros x 20 atributos. Para a necessidadade desse trabalho serão selecionados apenas os registros que fazem referência ao **Indicado** INF5-1 a INF5-5, filtro das principais **Prestadoras**, e eliminação dos atributos sem relevância. Além disso, foram eliminados os registros com dados faltantes (devido ao grande volume de dados válidos disponíveis) e realizada a padronização de caso e eliminação de acentuação. Todo o processo de tratamento dos dados foi realizado na ferramenta Knime (no code) que permite manipular e vizualiar os dados de forma fácil e rápida. O fluxo é exebido na figura abaixo.\n",
    "\n",
    "![image-2.png](https://raw.githubusercontent.com/wabastos/ML_Analytics/main/Figura_2.bmp)\n",
    "\n",
    "O arquivo resultante, com os dados válidos, possui 654.335 registros x 12 atributos, contendo os dados de todas as **Unidades Federativas (UF)** e seus **Municípios** associados aos seus **Indicadores**. \n",
    "Os atributos a serem utilizados no modelo estão listados abaixo e suas respectivas descrições:\n",
    "\n",
    "- Ano - Ano de amostragem dos dados (apenas ano de 2022)\n",
    "- Mês - Mês de amostragem dos dados (1 a 12)\n",
    "- Indicador - corresponde aos indicadores INF5-1 a INF5-5\n",
    "- Descrição - significado do indicador\n",
    "- Município - nome do município\n",
    "- UF - sigla do estado\n",
    "- Prestadora - nome da operadora\n",
    "- Resultado - (em %) que representa o menor valor dentre os indicadores download, upload, packtloss e jitter. Quanto maior o valor apurado melhor a avaliação do resultado\n",
    "- Número de Coletores - quantidade usuários medidos \n",
    "- Número de Medidas - número de medidas realizadas\n",
    "- Limite Inferior - limite de dados amostrais\n",
    "- Limite Superior - limite de dados amostrais\n",
    "- data - data composta em formato dd/mm/aaaa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2202cac4",
   "metadata": {},
   "source": [
    "### Préprocessamento dos dados\n",
    "Aqui limitaremos o escopo da base de dados apenas a todas as capitais brasileiras para minimizar o impacto computacional de tratamento dos modelos, embora possa ser empregado a um conjunto variado de possibilidades, até o total de registros.\n",
    "\n",
    "Passos:\n",
    "\n",
    "1. Leitura dos dados\n",
    "1. Define as listas de filtros por UF e Municípios\n",
    "1. Converte dados para representação numérica\n",
    "1. Avalia a base de dados (tipos de dados, shape e print de amostra)\n",
    "\n",
    "*Observação: uma vez que os dados foram pré-processados em ferramenta ETL, faremos aqui apenas uma avaliação dos tipos, shape e uma amostra aleatória de 20 registros.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "732d9991",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Ignorar todos os warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Carregar os dados\n",
    "url='https://raw.githubusercontent.com/wabastos/ML_Analytics/main/Tabela_CSV_Indicadores_RQUAL_Movel.csv'\n",
    "data_i = pd.read_csv(url,sep=';')\n",
    "\n",
    "# Filtrar a base de dados com base nos atributos UF e Municipio\n",
    "ufs = ['ba','se','al','pe','pb','rn','ce','pi','sp','rj','mg','es','df','pr','sc','rs','go','to',\n",
    "      'ms','mt','am','pa','ma','ac','ap','rr','ro']  # Lista de UF desejadas\n",
    "municipios = ['salvador','aracaju','maceio','recife', 'joao pessoa', 'natal','fortaleza','teresina',\n",
    "              'sao paulo', 'rio de janeiro','belo horizonte','vitoria','brasilia','curitiba',\n",
    "              'florianopolis','porto alegre','goiania','palmas','campo grande','cuiaba','manaus'\n",
    "              ,'belem','sao luis','rio branco','macapa','boa vista','porto velho']  # Lista de Municípios desejados\n",
    "\n",
    "#ufs = ['al']  # Lista de UF desejadas\n",
    "#municipios = []  # Lista de Municípios desejados\n",
    "n_medidas = 109\n",
    "\n",
    "# cópia dos dados para filtragem\n",
    "filtered_data_i = data_i\n",
    "\n",
    "# Verificar se a lista de municípios não está vazia\n",
    "if municipios:\n",
    "    filtered_data_i = filtered_data_i[filtered_data_i['Município'].isin(municipios)]\n",
    "\n",
    "# Verificar se a lista de UF não está vazia\n",
    "if ufs:\n",
    "    filtered_data_i = filtered_data_i[filtered_data_i['UF'].isin(ufs)]\n",
    "\n",
    "   \n",
    "\n",
    "# Substituir vírgulas por pontos nas colunas desejadas\n",
    "filtered_data_i['Resultado'] = filtered_data_i['Resultado'].str.replace(',', '.')\n",
    "filtered_data_i['Limite Inferior'] = filtered_data_i['Limite Inferior'].str.replace(',', '.')\n",
    "filtered_data_i['Limite Superior'] = filtered_data_i['Limite Superior'].str.replace(',', '.')\n",
    "\n",
    "# Converter as colunas para numérico\n",
    "filtered_data_i['Resultado'] = pd.to_numeric(filtered_data_i['Resultado'], errors='coerce')\n",
    "filtered_data_i['Limite Inferior'] = pd.to_numeric(filtered_data_i['Limite Inferior'], errors='coerce')\n",
    "filtered_data_i['Limite Superior'] = pd.to_numeric(filtered_data_i['Limite Superior'], errors='coerce')\n",
    "\n",
    "\n",
    "print(filtered_data_i.dtypes)\n",
    "print('\\nShape: ',filtered_data_i.shape)\n",
    "display(filtered_data_i.sample(n=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32eaca52",
   "metadata": {},
   "source": [
    "## Código: \n",
    "### Categorização dos resultados dos KPI's nos  Níveis: Superior, Inferior e Nivel_1 a 5\n",
    "\n",
    "1. filtra os atributos relevantes\n",
    "1. agrupa para reduzir o número de registros e consolidar atributos\n",
    "1. gera as classificações\n",
    "1. aplica as classes ao atributo \"Resultado\"\n",
    "1. plota a distribuição de classificações dos indicadores\n",
    "\n",
    "Essa classificação tem a finalidade de mostrar qual a distribuíção dos níveis de KPI ao longo de toda base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fed6d1c6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Selecione apenas as colunas relevantes para a agregação\n",
    "df_aggregated = filtered_data_i[['Ano','Mês','Indicador', 'Município', 'UF', 'Prestadora', 'Resultado', 'Número de Coletores', 'Número de Medidas',\n",
    "                                 'Limite Superior', 'Limite Inferior']]\n",
    "\n",
    "# Agrupe pelos parâmetros desejados e calcule a média do resultado, número de coletores e a soma do número de medidas\n",
    "filtered_data = df_aggregated.groupby(['Ano','Mês','Indicador', 'Município', 'UF', 'Prestadora']).agg({'Resultado': 'mean', 'Número de Coletores': 'mean', \n",
    "                                                                                            'Número de Medidas': 'sum', 'Limite Superior':'mean',\n",
    "                                                                                            'Limite Inferior':'mean'}).reset_index()\n",
    "\n",
    "# Exiba o resultado\n",
    "filtered_data = filtered_data_i\n",
    "\n",
    "# Calcular a média da diferença entre os limites\n",
    "difference = (filtered_data['Limite Superior'] - filtered_data['Limite Inferior'])/6\n",
    "\n",
    "# Definir as classes com base nos limites e na média da diferença\n",
    "conditions = [\n",
    "    (filtered_data['Resultado'] >= filtered_data['Limite Superior']),\n",
    "    (filtered_data['Resultado'] <= filtered_data['Limite Inferior']),\n",
    "    (filtered_data['Resultado'] > (filtered_data['Limite Superior'] - difference)),\n",
    "    (filtered_data['Resultado'] >= (filtered_data['Limite Superior'] - 2*difference)),\n",
    "    (filtered_data['Resultado'] > (filtered_data['Limite Superior'] - 3*difference)),\n",
    "    (filtered_data['Resultado'] >= (filtered_data['Limite Superior'] - 4*difference)),\n",
    "    (filtered_data['Resultado'] > (filtered_data['Limite Superior'] - 5*difference))\n",
    "]\n",
    "\n",
    "class_labels = ['Superior', 'Inferior', 'Nível_1', 'Nível_2', 'Nível_3', 'Nível_4', 'Nível_5']\n",
    "\n",
    "filtered_data['Classificacao'] = np.select(conditions, class_labels[:len(conditions)], default='Nível_6')\n",
    "\n",
    "#n = 1000 if filtered_data.shape[0] > 1000 else filtered_data.shape[0]\n",
    "n = filtered_data.shape[0] if filtered_data.shape[0] > 1000 else filtered_data.shape[0]\n",
    "\n",
    "filtered_data = filtered_data.sample(n=n)\n",
    "print(filtered_data.shape)\n",
    "\n",
    "# Contar as ocorrências de cada classe\n",
    "class_counts = filtered_data['Classificacao'].value_counts()\n",
    "\n",
    "# Criar o gráfico de barras\n",
    "plt.bar(class_counts.index, class_counts.values)\n",
    "plt.xlabel('Classificação')\n",
    "plt.ylabel('Contagem')\n",
    "plt.title('Contagem de Classes')\n",
    "plt.show()\n",
    "\n",
    "display(filtered_data)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb6c75fa",
   "metadata": {},
   "source": [
    "## Código:\n",
    "###  Treinando e Verificando o desempenho de  Modelos de ML para Classificação \n",
    "#### com Cross Validation\n",
    "\n",
    "Nessa parte do código, são utilizados diversos algoritmos de aprendizado de máquina para classificar os dados filtrados das capitais brasileiras. As variáveis preditoras são definidas como 'Indicador', 'Resultado', 'Número de Coletores' e 'Número de Medidas', e as variáveis alvo são 'Município' e 'Prestadora'. Abaixo está uma descrição resumida do algoritmo e seu uso:\n",
    "\n",
    "- O código cria uma pipeline de classificação que inclui vários modelos, como regressão logística, árvore de decisão, floresta aleatória, boosting, k-vizinhos mais próximos, SVM, Bagging, Extra Trees, AdaBoost e Voting.\n",
    "- Os dados são divididos em conjuntos de treinamento e teste.\n",
    "- O pré-processamento é aplicado as características numéricas usando a codificação 'StandardScaler' e as características categóricas usando a codificação 'OneHotEncoder' (ignorando valores desconhecidos).\n",
    "- Os modelos são avaliados usando a validação cruzada, servindo-se da pontuação de precisão como métrica (média da acurácia e desvio padrão).\n",
    "- Um resumo dos resultados é impresso, mostrando a média e o desvio padrão da precisão para cada modelo e atributo.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a92b3254",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "np.random.seed(54) # Definir a semente aleatória globalmente\n",
    "\n",
    "# Carregar os dados de entrada X e os rótulos y\n",
    "X = filtered_data[['Indicador', 'Resultado', 'Número de Coletores', 'Número de Medidas']]\n",
    "y = filtered_data[['Município', 'Prestadora']]\n",
    "\n",
    "# Dividir os dados em conjuntos de treinamento e teste\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=54)\n",
    "\n",
    "# Definir as características numéricas e categóricas\n",
    "numeric_features = ['Resultado', 'Número de Coletores', 'Número de Medidas']\n",
    "categorical_features = ['Indicador']\n",
    "\n",
    "# Definir os transformadores para as características numéricas e categóricas\n",
    "numeric_transformer = StandardScaler()\n",
    "categorical_transformer = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Definir o pré-processador que aplica as transformações nas características\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, numeric_features),\n",
    "        ('cat', categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "# Definir o modelo base para o BaggingClassifier\n",
    "base = DecisionTreeClassifier()\n",
    "num_trees = 100\n",
    "max_features = 3\n",
    "\n",
    "# Criar os modelos para o VotingClassifier\n",
    "bases = []\n",
    "model1 = LogisticRegression(max_iter=200)\n",
    "bases.append(('logistic', model1))\n",
    "model2 = DecisionTreeClassifier()\n",
    "bases.append(('cart', model2))\n",
    "model3 = SVC()\n",
    "bases.append(('svm', model3))\n",
    "\n",
    "# Definir os modelos a serem avaliados\n",
    "models = {\n",
    "    'Naive Bayes': GaussianNB(),\n",
    "    'Logistic Regression': model1,\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'KNN': KNeighborsClassifier(),\n",
    "    'SVM': model3,\n",
    "    'Bagging': BaggingClassifier(base_estimator=base, n_estimators=num_trees, max_features=max_features),\n",
    "    'Extra Trees': ExtraTreesClassifier(),\n",
    "    'AdaBoost': AdaBoostClassifier(),\n",
    "    'Voting': VotingClassifier(estimators=bases)\n",
    "}\n",
    "\n",
    "# Listas para armazenar os resultados das métricas\n",
    "scores_municipio_all = []\n",
    "scores_prestadora_all = []\n",
    "\n",
    "results = []\n",
    "\n",
    "# Iteragir sobre os modelos e avaliá-los\n",
    "for model_name, model in models.items():\n",
    "    \n",
    "    # Definir a semente aleatória para o modelo\n",
    "    model.random_state = 54\n",
    "\n",
    "    # Criar uma pipeline com pré-processamento e o modelo atual\n",
    "    pipeline = make_pipeline(preprocessor, model) \n",
    "    \n",
    "    # Definir o número de folds para a validação cruzada\n",
    "    n_folds = 5\n",
    "\n",
    "    # Definir o objeto KFold com a semente aleatória\n",
    "    kf = KFold(n_splits=n_folds, random_state=54, shuffle=True)\n",
    "   \n",
    "    # Validação cruzada para o atributo \"Município\"\n",
    "    scores_municipio = cross_val_score(pipeline, X_train, y_train['Município'], cv=kf, scoring='accuracy')\n",
    "    scores_municipio_all.append(scores_municipio)\n",
    "\n",
    "    # Validação cruzada para o atributo \"Prestadora\"\n",
    "    scores_prestadora = cross_val_score(pipeline, X_train, y_train['Prestadora'], cv=kf, scoring='accuracy')\n",
    "    scores_prestadora_all.append(scores_prestadora)\n",
    "\n",
    "    # Treinar a pipeline com os dados de treinamento para o atributo \"Município\"\n",
    "    pipeline.fit(X_train, y_train['Município'])\n",
    "\n",
    "    # Fazer previsões nos dados de teste para o atributo \"Município\"\n",
    "    y_pred_municipio = pipeline.predict(X_test)\n",
    "\n",
    "    # Treinar a pipeline com os dados de treinamento para o atributo \"Prestadora\"\n",
    "    pipeline.fit(X_train, y_train['Prestadora'])\n",
    "\n",
    "    # Resumo dos resultados\n",
    "    msg = \"%s(Municipio): %f (%f)\" % (model_name, scores_municipio.mean(), scores_municipio.std())\n",
    "    print(msg)\n",
    "    msg = \"%s(Prestadora): %f (%f)\" % (model_name, scores_prestadora.mean(), scores_prestadora.std())\n",
    "    print(msg)\n",
    "    print()\n",
    "\n",
    " # Resumo dos resultados\n",
    "    municipio_result = {\n",
    "        'Modelo': model_name,\n",
    "        'Atributo': 'Município',\n",
    "        'Média': scores_municipio.mean(),\n",
    "        'Desvio Padrão': scores_municipio.std()\n",
    "    }\n",
    "    results.append(municipio_result)\n",
    "    \n",
    "    prestadora_result = {\n",
    "        'Modelo': model_name,\n",
    "        'Atributo': 'Prestadora',\n",
    "        'Média': scores_prestadora.mean(),\n",
    "        'Desvio Padrão': scores_prestadora.std()\n",
    "    }\n",
    "    results.append(prestadora_result)\n",
    "\n",
    "# Criar um DataFrame com os resultados\n",
    "df_results = pd.DataFrame(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9e8fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exibir a tabela para markdown\n",
    "print(df_results.to_markdown())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b03318",
   "metadata": {},
   "source": [
    "## Código:\n",
    "### Plotagem do resultado - validação cruzada de vários modelos de classificação de ML\n",
    "Este trecho de código plota boxplots para visualizar os resultados da validação cruzada dos modelos nos atributos \"Município\" e \"Prestadora\".\n",
    "\n",
    "Esses gráficos permitem comparar visualmente as distribuições de precisão dos diferentes modelos nos atributos \"Município\" e \"Prestadora\", ajudando a identificar quais modelos são mais consistentes ou apresentam melhor desempenho."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a3c6af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Plot boxplot for \"Município\" scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(scores_municipio_all, labels=models.keys())\n",
    "plt.title(\"Cross-validation Scores - Município\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "plt.show()\n",
    "\n",
    "# Plot boxplot for \"Prestadora\" scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.boxplot(scores_prestadora_all, labels=models.keys())\n",
    "plt.title(\"Cross-validation Scores - Prestadora\")\n",
    "plt.xlabel(\"Models\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.xticks(rotation=90)  # Rotate x-axis labels by 90 degrees\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960419df",
   "metadata": {},
   "source": [
    "## Resultado:\n",
    "### Avaliando e escolhendo o Modelo ML mais adequado\n",
    "\n",
    "Observando os resultados dos modelos nos atributos \"Município\" e \"Prestadora\", podemos construir uma tabela com as seguintes observações/classificações de desempenho dos modelos. A mesma informação também pode ser comparada visualmente através dos gráficos boxplot:\n",
    "\n",
    "Exemplo de classificação de desempenho. É possível que execuções diferentes dos treinamentos sejam obtidos valores um pouco diferentes, mas muito próximos aos mostrados abaixo.\n",
    "\n",
    "|    | Modelo              | Atributo   | Desempenho         | Média    | Desvio Padrão |\n",
    "|---:|:--------------------|:-----------|:------------------|---------:|--------------:|\n",
    "|  0 | Naive Bayes         | Município  | Muito baixo        | 0.158571 |    0.0110049  |\n",
    "|  1 | Naive Bayes         | Prestadora | Moderado           | 0.399277 |    0.0171706  |\n",
    "|  2 | Logistic Regression | Município  | Baixo              | 0.165294 |    0.01362    |\n",
    "|  3 | Logistic Regression | Prestadora | Relativamente baixo| 0.383525 |    0.0122104  |\n",
    "|  4 | Decision Tree       | Município  | Bom                | 0.826186 |    0.0161867  |\n",
    "|  5 | Decision Tree       | Prestadora | Bom                | 0.780464 |    0.0606343  |\n",
    "|  6 | Random Forest       | Município  | Moderado           | 0.440336 |    0.0137406  |\n",
    "|  7 | Random Forest       | Prestadora | Relativamente bom  | 0.655471 |    0.0161653  |\n",
    "|  8 | Gradient Boosting   | Município  | Bom                | 0.836008 |    0.0163954  |\n",
    "|  9 | Gradient Boosting   | Prestadora | Bom                | 0.725466 |    0.0175389  |\n",
    "| 10 | KNN                 | Município  | Baixo              | 0.343491 |    0.00537801 |\n",
    "| 11 | KNN                 | Prestadora | Moderado           | 0.576697 |    0.0198359  |\n",
    "| 12 | SVM                 | Município  | Muito baixo        | 0.209974 |    0.0112229  |\n",
    "| 13 | SVM                 | Prestadora | Moderado           | 0.466683 |    0.0188612  |\n",
    "| 14 | Bagging             | Município  | Excelente          | 0.942407 |    0.0131375  |\n",
    "| 15 | Bagging             | Prestadora | Excelente          | 0.943442 |    0.010625   |\n",
    "| 16 | Extra Trees         | Município  | Moderado           | 0.42252  |    0.0108385  |\n",
    "| 17 | Extra Trees         | Prestadora | Relativamente bom  | 0.658312 |    0.00980442 |\n",
    "| 18 | AdaBoost            | Município  | Muito baixo        | 0.138942 |    0.0184834  |\n",
    "| 19 | AdaBoost            | Prestadora | Moderado           | 0.507741 |    0.0195436  |\n",
    "| 20 | Voting              | Município  | Baixo              | 0.307082 |    0.0124214  |\n",
    "| 21 | Voting              | Prestadora | Moderado           | 0.529959 |    0.0273567  |\n",
    "\n",
    "\n",
    "Com base nos resultados acima, o modelo mais adequado dependerá do atributo específico que estamos considerando. Para o atributo *\"Município\"*, o modelo *Bagging* obteve um desempenho excepcionalmente alto (excelente), com uma precisão média em torno de *0.95*. Para o atributo *\"Prestadora\"*, o modelo *Bagging* também teve um desempenho excelente, com uma precisão média em torno de *0.95*. Portanto, o modelo **Bagging** é uma escolha recomendada para ambos os atributos, pois apresentou consistência e bom desempenho nos experimentos realizados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d8740b",
   "metadata": {},
   "source": [
    "## Código: Criando os modelos model_municipio e model_prestadora\n",
    "### Algoritmo selecionado: BaggingClassifier\n",
    "#### Aplicando a Base de Testes\n",
    "\n",
    "O código cria uma pipeline com pré-processamento de dados e o modelo Bagging. Em seguida, ajusta a pipeline aos dados de treinamento para o atributo \"Município\" e faz a previsão dos dados de teste usando o modelo Bagging. Depois, ajusta a pipeline aos dados de treinamento para o atributo \"Prestadora\" e realiza a previsão novamente.\n",
    "\n",
    "O nome do modelo é obtido através do pipeline e, em seguida, são exibidos relatórios de classificação contendo métricas como precision, recall e f1-score, bem como a acurácia para cada atributo (\"Município\" e \"Prestadora\"). O objetivo é avaliar o desempenho do modelo Bagging em relação a esses atributos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e10359",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "model_name = 'BaggingClassifier'\n",
    "\n",
    "# Criar pipelines separadas para cada atributo\n",
    "pipeline_municipio = make_pipeline(preprocessor, BaggingClassifier(base_estimator=base, n_estimators=num_trees, \n",
    "                                                                   max_features=max_features))\n",
    "pipeline_prestadora = make_pipeline(preprocessor, BaggingClassifier(base_estimator=base, n_estimators=num_trees, \n",
    "                                                                    max_features=max_features))\n",
    "\n",
    "# Ajustar a pipeline no conjunto de treinamento para o atributo \"Município\"\n",
    "model_municipio = pipeline_municipio.fit(X_train, y_train['Município'])\n",
    "# Salvar o modelo ajustado para o atributo \"Município\"\n",
    "joblib.dump(model_municipio, 'model_municipio.pkl')\n",
    "\n",
    "# Ajustar a pipeline no conjunto de treinamento para o atributo \"Prestadora\"\n",
    "model_prestadora = pipeline_prestadora.fit(X_train, y_train['Prestadora'])\n",
    "# Salvar o modelo ajustado para o atributo \"Prestadora\"\n",
    "joblib.dump(model_prestadora, 'model_prestadora.pkl')\n",
    "\n",
    "# Prever os dados de teste usando os modelos ajustados\n",
    "y_pred_municipio = model_municipio.predict(X_test)\n",
    "y_pred_prestadora = model_prestadora.predict(X_test)\n",
    "\n",
    "\n",
    "# Calcular classification report e accuracy para o atributo \"Município\"\n",
    "municipio_report = classification_report(y_test['Município'], y_pred_municipio, output_dict=True)\n",
    "municipio_classes = list(municipio_report.keys())\n",
    "municipio_precision = [municipio_report[label]['f1-score'] for label in municipio_classes if label not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "\n",
    "# Calcular classification report e accuracy para o atributo \"Prestadora\"\n",
    "prestadora_report = classification_report(y_test['Prestadora'], y_pred_prestadora, output_dict=True)\n",
    "prestadora_classes = list(prestadora_report.keys())\n",
    "prestadora_precision = [prestadora_report[label]['f1-score'] for label in prestadora_classes if label not in ['accuracy', 'macro avg', 'weighted avg']]\n",
    "\n",
    "# Imprimir as informações formatadas\n",
    "print(f\"{model_name} - Município:\")\n",
    "print(classification_report(y_test['Município'], y_pred_municipio))\n",
    "print(f\"Accuracy: {accuracy_score(y_test['Município'], y_pred_municipio)}\")\n",
    "print(\"-------------------\")\n",
    "print()\n",
    "\n",
    "print(f\"{model_name} - Prestadora:\")\n",
    "print(classification_report(y_test['Prestadora'], y_pred_prestadora))\n",
    "print(f\"Accuracy: {accuracy_score(y_test['Prestadora'], y_pred_prestadora)}\")\n",
    "print(\"-------------------\")\n",
    "print()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2c0c7d",
   "metadata": {},
   "source": [
    "## Resultado:\n",
    "### Da aplicação do modelo\n",
    "\n",
    "Após a criação dos modelos **model_municipio** e **model_prestadora** utilizando o algoritmo **BaggingClassifier** e a aplicação dos mesmos na base de testes, foram obtidos os seguintes resultados:\n",
    "\n",
    "> **Modelo BaggingClassifier - Município**:\n",
    "O modelo para classificação por município apresentou uma acurácia geral em torno de  0.97. Ao analisar as métricas de precisão, recall e F1-score para cada classe, observou-se um desempenho bastante satisfatório na maioria das capitais e cidades avaliadas. Destaca-se o alto desempenho em cidades como Aracaju, Brasília, João Pessoa, Manaus, Natal, Porto Alegre, Recife, São Luís, Teresina e Vitória, onde o modelo alcançou 100% de precisão e recall. Além disso, a média das métricas macro e weighted avg também foi alta, demonstrando a eficácia geral do modelo na classificação dos municípios.\n",
    "\n",
    "> **Modelo BaggingClassifier - Prestadora**:\n",
    "Já o modelo para classificação por prestadora obteve uma acurácia em torno de de 0.96. As métricas de precisão, recall e F1-score para cada prestadora (Claro, TIM e Vivo) também foram bastante positivas, com valores acima de 0,94 para todas elas. Isso indica que o modelo teve um bom desempenho na identificação das prestadoras com base nos indicadores de telecomunicações. A média das métricas macro avg e weighted avg também foi alta, corroborando a eficácia geral do modelo nessa tarefa.\n",
    "\n",
    "Em resumo, os resultados obtidos com os modelos BaggingClassifier aplicados à base de testes demonstram a capacidade desses modelos em classificar corretamente os municípios e prestadoras com base nos indicadores de telecomunicações. Esses resultados são promissores e podem ser utilizados para aprimorar a análise e tomada de decisão no setor de telecomunicações, proporcionando uma melhor compreensão do desempenho e qualidade dos serviços em diferentes regiões e com diferentes prestadoras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b847e",
   "metadata": {},
   "source": [
    "## Código: Avaliação Gráfica dos modelos\n",
    "### Foco no F1-Score\n",
    "\n",
    "O código analisa a precisão do modelo BaggingClassifier para os atributos \"Município\" e \"Prestadora\" e gera gráficos de barras para visualização das métricas de precisão. Isso permite uma análise comparativa das classes e identificação daquelas com melhor desempenho no modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d43f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar e alinhar as classes\n",
    "municipio_classes = [label for label in y_test['Município'].unique() if label in municipio_classes]\n",
    "municipio_precision = [municipio_report[label]['f1-score'] for label in municipio_classes]\n",
    "\n",
    "\n",
    "prestadora_classes = [label for label in y_test['Prestadora'].unique() if label in prestadora_classes]\n",
    "prestadora_precision = [prestadora_report[label]['f1-score'] for label in prestadora_classes]\n",
    "\n",
    "\n",
    "# Criar uma lista de tuplas combinando as classes e precisões\n",
    "combined_data = list(zip(municipio_classes, municipio_precision))\n",
    "\n",
    "# Ordenar a lista combinada com base na precisão (segundo elemento da tupla)\n",
    "sorted_data = sorted(combined_data, key=lambda x: x[1])\n",
    "\n",
    "# Separar as classes e precisões ordenadas em listas separadas\n",
    "sorted_classes, sorted_precision = zip(*sorted_data)\n",
    "\n",
    "# Atribuir os valores ordenados às variáveis originais\n",
    "municipio_classes = sorted_classes\n",
    "municipio_precision = sorted_precision\n",
    "\n",
    "\n",
    "# Configurações dos gráficos\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Gráfico para o atributo \"Município\"\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(municipio_classes, municipio_precision)\n",
    "plt.xlabel('Município')\n",
    "plt.ylabel('F1-Score')\n",
    "plt.title('Precisão do modelo BaggingClassifier - Município')\n",
    "\n",
    "# Rotacionar os labels do eixo x\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "# Gráfico para o atributo \"Prestadora\"\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(prestadora_classes, prestadora_precision)\n",
    "plt.xlabel('Prestadora')\n",
    "plt.ylabel('F1-score')\n",
    "plt.title('Precisão do modelo BaggingClassifier - Prestadora')\n",
    "\n",
    "# Rotacionar os labels do eixo x\n",
    "plt.xticks(rotation='vertical')\n",
    "\n",
    "# Ajustes de layout\n",
    "plt.tight_layout()\n",
    "\n",
    "# Exibir os gráficos\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a7087d3",
   "metadata": {},
   "source": [
    "## Resultado:\n",
    "\n",
    "> F1-score muito alto, indicando um bom desempenho em termos de classificação para cada classe individualmente. Para o atributo \"Município\" e \"Prestadora\" demonstra que existe um equilíbrio entre as métricas de precisão e recall e que, nesse caso particular, está equivalente a acurácia. \n",
    "\n",
    "\n",
    "### Como avaliar\n",
    "A escolha entre a acurácia, precisão, recall e F1-score depende do contexto e dos objetivos do  problema.\n",
    "\n",
    "- Acurácia (accuracy): É uma medida geral que indica a taxa de classificações corretas feitas pelo modelo em relação ao total de amostras. É útil quando todas as classes têm importância semelhante e o objetivo é maximizar a taxa de acertos geral.\n",
    "\n",
    "- Precisão (precision): É a proporção de verdadeiros positivos (TP) em relação ao total de classificações positivas feitas pelo modelo (TP + FP). É útil quando o foco é reduzir os falsos positivos, ou seja, evitar classificar erroneamente amostras negativas como positivas.\n",
    "\n",
    "- Recall (revocação, sensibilidade, taxa de verdadeiros positivos): É a proporção de verdadeiros positivos (TP) em relação ao total de amostras positivas reais (TP + FN). É útil quando o objetivo é reduzir os falsos negativos, ou seja, evitar classificar erroneamente amostras positivas como negativas.\n",
    "\n",
    "- F1-score: É uma métrica que combina precisão e recall em um único valor. É útil quando você deseja levar em consideração tanto os falsos positivos quanto os falsos negativos. O F1-score é a média harmônica entre precisão e recall, fornecendo um equilíbrio entre as duas métricas. É especialmente útil quando as classes estão desequilibradas.\n",
    "\n",
    "A escolha da métrica depende do impacto dos falsos positivos e falsos negativos no problema. Se ambos são igualmente prejudiciais, o F1-score é uma métrica adequada. Se há necessidae de minimizar os falsos positivos, a precisão é relevante. Se a minimização dos falsos negativos é mais crítica, o recall é importante. Em alguns casos, é necessário analisar essas métricas em conjunto com outras informações e considerar a natureza específica do problema para tomar a melhor decisão.\n",
    "\n",
    "Lembrando que essas métricas fornecem uma visão geral do desempenho do modelo, mas é importante considerar outros fatores, como a distribuição das classes, o custo associado aos erros de classificação e as necessidades específicas do seu projeto.\n",
    "\n",
    "https://vitorborbarodrigues.medium.com/m%C3%A9tricas-de-avalia%C3%A7%C3%A3o-acur%C3%A1cia-precis%C3%A3o-recall-quais-as-diferen%C3%A7as-c8f05e0a513c\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a4314c9",
   "metadata": {},
   "source": [
    "*******************\n",
    "##  Insights\n",
    "*******************\n",
    "Neste contexto, propõe-se a aplicação prática dos indicadores de telecomunicações utilizando os modelos previamente desenvolvidos. O objetivo principal é realizar uma análise cruzada para identificar correlações e similaridades entre os indicadores RQUAL (INF5) das cidades brasileiras e um conjunto de referência composto pelas principais capitais dos estados e o Distrito Federal. Através dessa abordagem, busca-se identificar quais capitais possuem um perfil de indicador correlacionado ou apresentam semelhanças com os indicadores das cidades em questão.\n",
    "\n",
    "Essa técnica, se validada, pode oferecer diversas vantagens, permitindo uma análise mais aprofundada dos perfis de usuários, tráfego, sazonalidades, desempenho da rede e outras métricas relevantes, como latência, perda de pacotes, velocidade de uplink e downlink, entre outros. Além disso, possibilitaria uma melhor compreensão dos padrões e comportamentos das telecomunicações, auxiliando no diagnóstico de problemas (troubleshooting) e no dimensionamento de capacidades.\n",
    "\n",
    "Em suma, essa abordagem de análise e comparação dos indicadores de telecomunicações entre as cidades brasileiras e as capitais de referência amplia as possibilidades de análise e pode fornecer insights valiosos para aprimorar a qualidade e eficiência dos serviços de telecomunicações em todo o país\n",
    "\n",
    "Como faremos:\n",
    "\n",
    "1. definiremos uma base de comparação (chamada external data)\n",
    "1. aplicaremos essa base aos modelos treinados (model_municipio e model_prestadora)\n",
    "1. compor uma  base de comparação entre o perfil dos indicadores das cidades em foco (modelados) e as capitais de referência (base externa)\n",
    "1. analisar os dados de forma exploratória em busca de fatos relevantes ou insights\n",
    "> - contagem de ocorrências\n",
    "> - agregação e frequência\n",
    "> - teste de variância - ANOVA\n",
    "> - teste de independência\n",
    "> - análise de clusterização"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15477c09",
   "metadata": {},
   "source": [
    "## Código: Leitura dos dados externos\n",
    "\n",
    "Código para leitura dos dados de comparação (foco) para três cidades da região sul (Maringá, Blumenal e Novo Hamburgo). A escolha foi feita por similaridade de perfil populacional das cidades, de forma que a minimizar distorções por perfil de amostras válidas para formação dos KPI's. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23b8bd0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Filtrar a base de dados com base nos atributos UF e Municipio\n",
    "ufs = ['rs','sc','pr']  # Lista de UF desejadas\n",
    "municipios = ['novo hamburgo','blumenau','maringa']  # Lista de Municípios desejados\n",
    "\n",
    "\n",
    "# cópia dos dados para filtragem\n",
    "filtered_data_ii = data_i\n",
    "\n",
    "# Verificar se a lista de municípios não está vazia\n",
    "if municipios:\n",
    "    filtered_data_ii = filtered_data_ii[filtered_data_ii['Município'].isin(municipios)]\n",
    "\n",
    "# Verificar se a lista de UF não está vazia\n",
    "if ufs:\n",
    "    filtered_data_ii = filtered_data_ii[filtered_data_ii['UF'].isin(ufs)]\n",
    "\n",
    "    \n",
    "# Substituir vírgulas por pontos nas colunas desejadas\n",
    "filtered_data_ii['Resultado'] = filtered_data_ii['Resultado'].str.replace(',', '.')\n",
    "filtered_data_ii['Limite Inferior'] = filtered_data_ii['Limite Inferior'].str.replace(',', '.')\n",
    "filtered_data_ii['Limite Superior'] = filtered_data_ii['Limite Superior'].str.replace(',', '.')\n",
    "\n",
    "\n",
    "# Converter as colunas para numérico\n",
    "filtered_data_ii['Resultado'] = pd.to_numeric(filtered_data_ii['Resultado'], errors='coerce')\n",
    "filtered_data_ii['Limite Inferior'] = pd.to_numeric(filtered_data_ii['Limite Inferior'], errors='coerce')\n",
    "filtered_data_ii['Limite Superior'] = pd.to_numeric(filtered_data_ii['Limite Superior'], errors='coerce')\n",
    "\n",
    "# Imprime so tipos de dados, o shape da base e uma amostra dos dados\n",
    "print(filtered_data_ii.dtypes)\n",
    "print('\\nShape: ',filtered_data_ii.shape)\n",
    "display(filtered_data_ii.sample(n=10))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8d3f794",
   "metadata": {},
   "source": [
    "## Código: aplicação dos dados externos aos modelos\n",
    "\n",
    "1. Aplica os dados externos aos modelos\n",
    "1. Adiciona a base externa os resultados obtidos\n",
    "1. Elimina atributos não significativos (opcional)\n",
    "1. Imprime o dataframe resultante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a0aaaf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Use o modelo Bagging treinado para fazer previsões nos dados externos\n",
    "y_pred_municipio_external = model_municipio.predict(filtered_data_ii)\n",
    "y_pred_prestadora_external = model_prestadora.predict(filtered_data_ii)\n",
    "\n",
    "# Criar um cópia do dataframe para armazenar os resultados\n",
    "df_resultados = filtered_data_ii.copy()\n",
    "\n",
    "# Adicionar as colunas dos resultados ao dataframe\n",
    "df_resultados['Resultado Município'] = y_pred_municipio_external\n",
    "df_resultados['Resultado Prestadora'] = y_pred_prestadora_external\n",
    "\n",
    "\n",
    "# Remover as colunas indesejadas do dataframe\n",
    "atributos_removidos = [\"Número de Coletores\", \"Limite Inferior\", \"Limite Superior\",'data']\n",
    "df_resultados = df_resultados.drop(atributos_removidos, axis=1)\n",
    "\n",
    "# Imprimir o dataframe atualizado\n",
    "print(\"Dataframe com os resultados (sem os atributos removidos):\")\n",
    "display(df_resultados)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e03057d",
   "metadata": {},
   "source": [
    "## Código: Contagem simples\n",
    "\n",
    "1. Realiza uma contagem de Municípios (foco) e lista em relação aos Municípios de Referência (aqui chamado de Resultado Município)\n",
    "1. Imprime duas listas com as contagens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94bb9b0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Contagem de ocorrências diferentes de \"Municipio\" na coluna \"Resultado Municipio\"\n",
    "contagem_municipio = df_resultados.loc[df_resultados['Resultado Município'] != 'Município', 'Resultado Município'].value_counts()\n",
    "\n",
    "# Contagem de ocorrências diferentes de \"Municipio\" na coluna \"Resultado Prestadora\"\n",
    "contagem_prestadora = df_resultados.loc[df_resultados['Resultado Prestadora'] != 'Município', 'Resultado Prestadora'].value_counts()\n",
    "\n",
    "# Imprimir as contagens\n",
    "print(\"Contagem de ocorrências diferentes de 'Municipio' na coluna 'Resultado Municipio':\")\n",
    "print(contagem_municipio)\n",
    "print()\n",
    "\n",
    "print(\"Contagem de ocorrências diferentes de 'Municipio' na coluna 'Resultado Prestadora':\")\n",
    "print(contagem_prestadora)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1b9fcf",
   "metadata": {},
   "source": [
    "## Resultado:\n",
    "### Contagem simples\n",
    "Após a análise dos resultados utilizando o modelo BaggingClassifier nos atributos \"Município\" e \"Prestadora\", podemos observar que o resultado não é conclusivo e possui pouca relevância no contexto geral. No entanto, foi identificado que as capitais com populações menores, que possuem certa equivalência aos municípios de interesse, podem apresentar uma maior similaridade de perfil. Embora ainda não possamos estabelecer uma correlação ou equivalência significativa, esse fator pode se mostrar importante em análises futuras."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdf53918",
   "metadata": {},
   "source": [
    "## Código:\n",
    "### Agregação e frequencia de atributos\n",
    "\n",
    "1. sumariza os dados através de agrupamentos dos atributos selecionados\n",
    "1. filtra por Prestadora\n",
    "1. ordena por atributos selecionados\n",
    "1. imprime tabela completa\n",
    "1. seleciona e imprime os máximos valores pos município foco\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01c4ce38",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Criar a tabela de correspondência e contar as ocorrências de \"Resultado Município\" por \"Municipio\"\n",
    "tabela_municipio = df_resultados.groupby(['Município', 'Resultado Município', 'Prestadora']).agg({'Número de Medidas': 'sum'}).reset_index()\n",
    "tabela_municipio['Quantidade'] = df_resultados.groupby(['Município', 'Resultado Município', 'Prestadora']).size().reset_index(name='Size')['Size']\n",
    "\n",
    "# Filtrar os dados apenas para a prestadora \n",
    "#data_cidade = tabela_municipio[tabela_municipio['Prestadora'] != ' ']\n",
    "data_cidade = tabela_municipio[tabela_municipio['Prestadora'] == 'vivo']\n",
    "data_cidade = data_cidade.sort_values(by=[ 'Número de Medidas','Quantidade'], ascending=False)\n",
    "\n",
    "\n",
    "# Imprimir a tabela de correspondência com a correlação\n",
    "print(\"Tabela de correspondência entre 'Resultado Município' e 'Município' com contagem de ocorrências e correlação:\")\n",
    "print(data_cidade.to_markdown())\n",
    "\n",
    "\n",
    "# Imprimir apenas os maiores valores por município\n",
    "max_values = data_cidade.groupby('Município').head(3)\n",
    "print(\"\\nMaiores valores por município:\")\n",
    "print(max_values.to_markdown())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c4322be",
   "metadata": {},
   "source": [
    "## Resultado:\n",
    "\n",
    "\n",
    "Ao analisar a tabela de maiores valores em relação ao atributo \"Resultado Município\" e compará-la com a tabela geral, podemos fazer uma avaliação parcial sobre a existência de simetria ou equivalência entre os municípios da coluna \"Município\" e o resultado registrado na coluna \"Resultado Município\". No entanto, é importante ressaltar que essa análise é limitada e requer uma investigação mais aprofundada para obter conclusões mais sólidas.\n",
    "\n",
    "Observando os resultados específicos para cada município, podemos fazer as seguintes observações iniciais:\n",
    "\n",
    "Blumenau:\n",
    "\n",
    "> O município de Blumenau apresenta uma diversidade de resultados no atributo \"Resultado Município\", incluindo \"Natal\", \"Boa vista\",\"Florianópolis\", \"Cuiabá\" e \"João Pessoa\". Essa variedade sugere que Blumenau tem uma presença abrangente e não está restrito a um único resultado específico. Essa diversidade pode indicar uma equivalência parcial com esses municípios em termos de perfil e características.\n",
    "\n",
    "Maringá:\n",
    "\n",
    "> O município de Maringá também exibe uma diversidade de resultados, como \"Teresina\", \"Porto Velho\" e \"Boa Vista\". Essa variedade indica que Maringá possui uma presença em diferentes resultados, o que pode indicar uma equivalência parcial com esses municípios em termos de perfil e características.\n",
    "\n",
    "Novo Hamburgo:\n",
    "\n",
    "> Da mesma forma, Novo Hamburgo apresenta resultados variados, incluindo \"Vitória\", \"Porto Velho\" e \"Boa Vista\". Essa diversidade sugere uma possível simetria ou equivalência parcial com esses municípios, indicando que Novo Hamburgo compartilha algumas características semelhantes com essas localidades.\n",
    "\n",
    "No entanto, é fundamental ressaltar que essas observações iniciais não são conclusivas e devem ser complementadas por análises estatísticas mais robustas. Além disso, é necessário considerar outros fatores, como características demográficas e geográficas, para obter uma compreensão mais completa das relações entre os municípios e os resultados registrados. A natureza específica dos dados e o contexto em que estão sendo utilizados também devem ser levados em conta para evitar generalizações indevidas. Portanto, é recomendável uma análise mais aprofundada antes de tirar conclusões definitivas sobre a simetria ou equivalência entre os municípios e os resultados apresentados.\n",
    "\n",
    "Para realizar uma análise estatística mais robusta em relação a avaliação da simetria ou equivalência entre os municípios da coluna \"Município\" e os resultados na coluna \"Resultado Município\", algumas abordagens podem ser consideradas:\n",
    "\n",
    "1. Análise de variância (ANOVA): A ANOVA é uma técnica estatística usada para comparar médias de três ou mais grupos. Poderíamos aplicar a ANOVA para verificar se há diferenças significativas nos resultados entre os diferentes municípios, permitindo identificar se existe uma relação estatisticamente significativa entre as variáveis.\n",
    "\n",
    "1. Teste de qui-quadrado: O teste de qui-quadrado é um teste estatístico que pode ser usado para verificar se existe uma associação significativa entre duas variáveis categóricas. Nesse caso, poderíamos aplicar o teste de qui-quadrado para avaliar se há uma relação significativa entre os municípios e os resultados registrados, verificando se as frequências observadas são diferentes das frequências esperadas.\n",
    "\n",
    "1. Análise de cluster: A análise de cluster é uma técnica estatística que agrupa objetos ou indivíduos semelhantes em grupos homogêneos. Nesse caso, poderíamos realizar uma análise de cluster para identificar agrupamentos de municípios com base nos resultados registrados, o que poderia indicar a presença de grupos de municípios com perfis semelhantes.\n",
    "\n",
    "\n",
    "\n",
    "Essas são apenas algumas das análises estatísticas mais comumente utilizadas. A escolha da técnica dependerá da natureza dos dados, do objetivo da análise e das suposições periféricas aos métodos estatísticos. **É recomendável consultar um especialista em estatística para realizar uma análise mais aprofundada e adequada ao contexto específico do estudo**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8cb0673",
   "metadata": {},
   "source": [
    "## Código ANOVA:\n",
    "\n",
    "O código apresentado a seguir realiza uma análise de variância (ANOVA) em diferentes municípios equivalentes, obtidos a partir do município foco. Inicialmente, é feito um filtro nos dados para cada município em questão, selecionando os resultados específicos. Em seguida, é aplicada a ANOVA nos dados filtrados. Os resultados da estatística F e do valor de p são armazenados e exibidos para cada município. Por fim, os resultados são adicionados a um DataFrame. O código fornece uma análise estatística dos indicadores em diferentes municípios, permitindo a comparação das médias dos grupos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2855090d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# define o mesmo filtro usado na leitura dos dados externos\n",
    "municipios_filtro = municipios\n",
    "results = []\n",
    "\n",
    "for municipio_filtro in municipios_filtro:\n",
    "    # Aplicar filtro ao DataFrame\n",
    "    filtro = max_values['Município'] == municipio_filtro\n",
    "    resultado_municipio_filtrado = max_values.loc[filtro, 'Resultado Município'].tolist()\n",
    "\n",
    "    df = df_resultados.copy()\n",
    "    df = df[df['Município'].isin([municipio_filtro])]\n",
    "    df = df[df['Resultado Município'].isin(resultado_municipio_filtrado)]\n",
    "\n",
    "    # Aplicar a ANOVA\n",
    "    result = df.groupby('Resultado Município').apply(lambda x: x[['Número de Medidas', 'Resultado']].values.tolist())\n",
    "\n",
    "    f_statistic, p_value = f_oneway(*result)\n",
    "\n",
    "    # Adicionar resultados à lista 'results'\n",
    "    for i, grupo in enumerate(result.index):\n",
    "        for row in result[i]:\n",
    "            results.append([grupo] + row)\n",
    "\n",
    "    # Exibir os resultados\n",
    "    print('Município Foco:', municipio_filtro)\n",
    "    print('Município Equivalente:\\n', result)\n",
    "    print(\"Estatística F:\", f_statistic)\n",
    "    print(\"Valor de p:\", p_value)\n",
    "    print('-----------------')\n",
    "\n",
    "# Criar DataFrame 'result' a partir da lista 'results'\n",
    "result = pd.DataFrame(results, columns=['Resultado Município', 'Número de Medidas', 'Resultado'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1457dc67",
   "metadata": {},
   "source": [
    "## Resultado: análise ANOVA\n",
    "\n",
    "A análise de variância (ANOVA) é um teste estatístico que compara a variação entre grupos com a variação dentro dos grupos. No contexto da nossa análise, foram aplicados testes de ANOVA em diferentes municípios foco (Novo Hamburgo, Blumenau e Maringá) para comparar o resultado de um indicador em diferentes medidas nos municípios equivalentes, obtidos a partir da aplicação dos modelos de aprendizado de máquina de classificação.\n",
    "\n",
    "Ao interpretar os resultados da ANOVA, podemos considerar os seguintes pontos:\n",
    "\n",
    "Estatística F: A estatística F é usada para determinar se existe diferença significativa entre as médias dos grupos. Quanto maior o valor da estatística F, maior é a diferença entre as médias dos grupos.\n",
    "\n",
    "Valor de p: O valor de p indica a probabilidade de obter os resultados observados se a hipótese nula for verdadeira. Geralmente, um valor de p menor que um determinado limite (como 0,05) é considerado estatisticamente significativo. Nesse caso, rejeita-se a hipótese nula e conclui-se que há diferença significativa entre as médias dos grupos.\n",
    "> Hipótese nula (H0): A hipótese nula afirma que não há diferenças significativas nas médias dos grupos. Portanto, assume-se que todos os grupos têm a mesma média.\n",
    "\n",
    "**Interpretação:**\n",
    "Os valores calculados para F e p são representados pelas duplas [F1, F2] e [p1, p2], correspondendo às medidas \"Número de Medidas\" e \"Resultado\".\n",
    "\n",
    "Exemplo:\n",
    "- Estatística F: [0.74269842 0.24477983]\n",
    "- Valor de p: [0.48197322 0.78398592]\n",
    "\n",
    "Para o indicador em análise em Novo Hamburgo, o valor de p é maior que 0,05 para ambas as variáveis (Número de Medidas e Resultado), indicando que não há diferença significativa entre as médias dos grupos. Portanto, não há evidências estatísticas suficientes para concluir que as medidas diferem significativamente entre os grupos. Em outras palavras, estatisticamente, os municípios são equivalentes entre si em relação ao perfil dos indicadores observados.\n",
    "\n",
    "Da mesma forma, os resultados podem ser interpretados para os outros municípios (Blumenau e Maringá) e suas respectivas variáveis (Número de Medidas e Resultado).\n",
    "\n",
    "Lembrando que a interpretação dos resultados da ANOVA deve levar em consideração o contexto específico do problema e outras análises complementares, se necessário.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f90dda5",
   "metadata": {},
   "source": [
    "## Código Qui-Quadrado:\n",
    "\n",
    "O código abaixo está calculando o teste de independência de qui-quadrado entre as variáveis \"Município\" e \"Resultado Município\" usando a tabela de contingência. O teste de qui-quadrado é uma medida estatística que permite determinar se existe uma associação significativa entre duas variáveis categóricas.\n",
    "\n",
    "O teste qui-quadrado avalia se a distribuição observada na tabela de contingência é significativamente diferente da distribuição esperada se as duas variáveis fossem independentes. Um valor de p-value menor que 0.05 indica uma associação significativa entre as variáveis.\n",
    "\n",
    "Lembrando que essa análise pressupõe que as variáveis 'Município' e 'Resultado Município' sejam categóricas.Portanto, não será necessário realizar uma transformação adequada ou utilizar outra técnica estatística."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07cc2bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data_selected = tabela_municipio[['Município', 'Resultado Município']]\n",
    "contingency_table = pd.crosstab(data_selected['Município'], data_selected['Resultado Município'])\n",
    "\n",
    "display(contingency_table)\n",
    "\n",
    "chi2, p_value, _, _ = chi2_contingency(contingency_table)\n",
    "print(\"\\nResultado Qui-Quadrado:\")\n",
    "if p_value < 0.05:\n",
    "    print(\"Existe uma associação significativa entre o município e o resultado do município.\")\n",
    "else:\n",
    "    print(\"Não há uma associação significativa entre o município e o resultado do município.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7777b8d",
   "metadata": {},
   "source": [
    "## Resultado: Qui-Quadrado\n",
    "\n",
    "O resultado foi obtido a parti de uma tabela de contingência que mostra a frequência com que os diferentes valores da variável \"Resultado Município\" ocorrem em cada município. A resposta indica que não há uma associação significativa entre o município e o resultado do município quando comparada a frequência de relacionamento entre eles. Isso implica que a variável \"Município\" não está relacionada de forma significativa com a variável \"Resultado Município\". Em outras palavras, as diferenças nos resultados observados nos municípios não podem ser atribuídas exclusivamente à variável \"Município\". Portanto, não há evidências estatísticas suficientes para concluir que o \"Município\" tem um impacto significativo no \"Resultado do município\". Essa interpretação é feita com base no valor de p obtido a partir do teste qui-quadrado de contingência, em que um valor de p maior que 0,05 indica a falta de associação significativa.\n",
    "\n",
    "Na verdade, esse resultado é até esperado, visto que os dados mostram claramente que o perfil dos indicadores do município alvo pode ser encontrado em vários municípios equivalentes e se repitir  apenas em alguns intervalos de tempo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ceb912",
   "metadata": {},
   "source": [
    "## Código: Clusterização Kmodes\n",
    "\n",
    "O código abaixo realiza a análise de clusterização usando o algoritmo K-Modes em um conjunto de dados categóricos. Primeiramente, os dados são carregados e é aplicada a codificação de rótulos às colunas categóricas usando o LabelEncoder. Em seguida, o algoritmo K-Modes é aplicado para realizar a clusterização, definindo o número desejado de clusters como 3.\n",
    "\n",
    "Em seguida, é realizada a redução de dimensionalidade dos dados usando o PCA, transformando os dados em duas componentes principais (PC1 e PC2). Um novo dataframe é criado com as componentes principais e os clusters. Os clusters são plotados em um gráfico de dispersão usando as componentes principais, onde cada cluster é representado por uma cor diferente. \n",
    "\n",
    "O código fornece insights sobre a distribuição dos dados nos clusters e ajuda a identificar possíveis padrões ou agrupamentos nos dados categóricos analisados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01f13479",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# Carregar os dados\n",
    "data = data_cidade.copy()\n",
    "\n",
    "# Aplicar a codificação de rótulos para as colunas categóricas\n",
    "label_encoder = LabelEncoder()\n",
    "for col in data.select_dtypes(include=['object']):\n",
    "    data[col] = label_encoder.fit_transform(data[col])\n",
    "\n",
    "# Realizar o clustering com K-Modes\n",
    "k = 3  # número de clusters desejado\n",
    "kmodes = KModes(n_clusters=k, random_state=42)\n",
    "clusters = kmodes.fit_predict(data)\n",
    "\n",
    "# Adicionar as informações dos clusters ao dataframe original\n",
    "data['Cluster'] = clusters\n",
    "\n",
    "\n",
    "# Reduzir a dimensionalidade dos dados com PCA\n",
    "pca = PCA(n_components=2)\n",
    "principal_components = pca.fit_transform(data)\n",
    "\n",
    "# Criar um dataframe com os componentes principais e os clusters\n",
    "df = pd.DataFrame(data=principal_components, columns=['PC1', 'PC2'])\n",
    "df['Cluster'] = clusters\n",
    "\n",
    "# Plotar os clusters\n",
    "plt.figure(figsize=(10, 6))\n",
    "scatter = plt.scatter(df['PC1'], df['PC2'], c=df['Cluster'], cmap='viridis')\n",
    "plt.legend(handles=scatter.legend_elements()[0], labels=range(k))\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.title('Clusters')\n",
    "plt.show()\n",
    "\n",
    "sorted_df = df.sort_values(by='Cluster')\n",
    "display(sorted_df)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f77d7bf5",
   "metadata": {},
   "source": [
    "## Resultado: Clusterização Kmodes\n",
    "**Pressuposto:**\n",
    "A interpretação da densidade de pontos em uma região do gráfico pode fornecer insights sobre a concentração ou dispersão dos pontos de dados em relação aos clusters. Uma alta densidade de pontos indica maior proximidade e similaridade entre as observações dentro do contexto dos atributos considerados, enquanto uma densidade baixa sugere dispersão e maior variabilidade. A densidade de pontos também pode revelar subgrupos ou padrões distintos dentro dos clusters. No entanto, a interpretação depende dos dados, das características categóricas e dos métodos de redução de dimensionalidade aplicados, exigindo uma análise em conjunto com o conhecimento do domínio e das características específicas dos dados.\n",
    "\n",
    "**Interpretação do gráfico: Exemplo**\n",
    "\n",
    "A partir da tabela de agrupamentos e da interpretação fornecida, podemos inferir que:\n",
    "\n",
    "![image.png](https://raw.githubusercontent.com/wabastos/ML_Analytics/main/Figura_3.bmp)\n",
    "\n",
    "- O Cluster 0 possui uma dispersão maior em relação às suas características, sugerindo uma variabilidade significativa nos atributos dos dados. No entanto, é possível identificar alguns agrupamentos que podem representar subgrupos de amostras com características semelhantes.\n",
    "- O Cluster 1 apresenta uma dispersão menor em comparação ao Cluster 0 e não mostra evidências claras de subgrupos, indicando que as amostras desse cluster têm características mais homogêneas.\n",
    "- O Cluster 2 exibe um agrupamento mais denso de suas características, com uma leve separação dos pontos em dois subgrupos próximos.\n",
    "\n",
    "Além disso, considerando que cada cluster representa uma associação entre municípios, com um município alvo e outros supostamente equivalentes, é possível inferir que a concentração desses pontos em uma região do gráfico, mesmo que em clusters diferentes, pode representar similaridades de características entre os municípios associados em um mesmo cluster ou diferentes. Portanto, é razoável afirmar que, para algumas características situacionais, os municípios possuem associações em comum dentro dentro e entre clusteres.\n",
    "\n",
    "Essa pode ser mais uma evidência, mesmo que por inferência da associação dos comportamento dos indicadores dos municípios foco e seus equivalentes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c70b3e9c",
   "metadata": {},
   "source": [
    "## Conclusão dos Insights:\n",
    "\n",
    "Nas seções de código acima (denominada Insights), realizamos quatro testes para verificar se o uso do modelo de referência, treinado com as capitais brasileiras, é adequado para encontrar similaridades entre municípios.\n",
    "\n",
    "Testes Aplicados:\n",
    "\n",
    "> - Contagem simples\n",
    "> - Análise de Variância - ANOVA\n",
    "> - Teste Qui-Quadrado\n",
    "> - Clusterização - K-modes\n",
    "\n",
    "Com base nas observações feitas a partir dos resultados dos testes, podemos inferir que, embora não sejam conclusivos, o uso do método sugerido pode indicar ao analista um caminho a ser seguido para compreender quais municípios possuem similaridades de perfil e comportamento em relação aos indicadores de rede. Isso pode ser de grande valia para o analista, pois pode agilizar a análise e orientar as ações a serem adotadas para manter ou corrigir a rede, resultando em melhorias no desempenho dessas cidades."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c76f51",
   "metadata": {},
   "source": [
    "## Conclusão Final\n",
    "\n",
    "Na Sprint II - letra a, enfrentamos o desafio de executar todo o pipeline de aplicação de ML, abrangendo desde a escolha do conjunto de dados e a contextualização do problema, até a normalização e codificação dos dados, a aplicação de vários modelos de ML, diferentes tipos de validação e testes, a avaliação dos modelos para determinar a escolha mais adequada ao problema, a aplicação dos modelos aos dados de interesse e a obtenção de insights e entendimento dos resultados.\n",
    "\n",
    "Além de buscar um resultado prático e aplicável, nesta fase de aprendizado é crucial compreender os conceitos e explorar as diversas abordagens e práticas disponíveis para a aplicação do ML como uma ferramenta de análise e apoio à tomada de decisões.\n",
    "\n",
    "Ao analisarmos os resultados obtidos no treinamento dos modelos, observamos uma variação significativa na acurácia entre os diferentes modelos testados. Isso ressalta a importância de realizar uma avaliação criteriosa dos modelos de Machine Learning, levando em consideração seu desempenho, consistência e adequação ao problema em questão. Essa análise nos permite selecionar o modelo mais apropriado para obter resultados práticos e aplicáveis, além de destacar a diversidade de abordagens e práticas disponíveis na exploração do Machine Learning como ferramenta de análise e apoio a tomada de decisão.\n",
    "\n",
    "É importante ressaltar que a variação dos hiperparâmetros poderia melhorar o desempenho de alguns modelos. No entanto, isso exigiria um tempo adicional de análise e resultaria em um aumento no custo computacional. Considerando que o modelo Bagging Classifier demonstrou ser adequado aos dados e suas características, decidimos prosseguir com esse modelo nas fases subsequentes de aplicação prática.\n",
    "\n",
    "Com base nos resultados do método proposto de avaliação dos indicadores RQUAL dos municípios, especialmente INF5, podemos concluir, mesmo preliminarmente, que é possível treinar um modelo de Machine Learning para um grupo de municípios e, por meio da similaridade de perfil, obter o perfil de outros municípios. Porém, para que isso seja possível é necessário garantir  as similaridades através de análise estatítica robusta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db2e97",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
